{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Facial-Similarity-with-Siamese-Networks-in-Pytorch' already exists and is not an empty directory.\n",
      "mkdir: cannot create directory ‘data’: File exists\n",
      "mv: cannot stat 'Facial-Similarity-with-Siamese-Networks-in-Pytorch/data/faces/testing/*': No such file or directory\n",
      "mv: cannot stat 'Facial-Similarity-with-Siamese-Networks-in-Pytorch/data/faces/training/*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/harveyslash/Facial-Similarity-with-Siamese-Networks-in-Pytorch.git\n",
    "!mkdir data\n",
    "!mv Facial-Similarity-with-Siamese-Networks-in-Pytorch/data/faces/testing/* data/\n",
    "!mv Facial-Similarity-with-Siamese-Networks-in-Pytorch/data/faces/training/* data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n",
    "\n",
    "from aijack.attack import MI_FACE\n",
    "from aijack.defense import GeneralMomentAccountant, DPSGDManager\n",
    "from aijack.utils import NumpyDataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from aijack.attack.membership import ShadowMembershipInferenceAttack\n",
    "from aijack.utils.utils import TorchClassifier, NumpyDataset\n",
    "\n",
    "BASE = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load mnist dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "#import shuffle from sklearn\n",
    "from sklearn.utils import shuffle\n",
    "#one hot encode from sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#shuffle the dataset\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "\n",
    "# downsample X_train and y_train to 1000 samples\n",
    "X_train = X_train[:1000]\n",
    "y_train = y_train[:1000]\n",
    "\n",
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)\n",
    "# reshaping data\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "#normalizing data\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#splitting train dataset into train and shadow dataset\n",
    "X_train, X_shadow, y_train, y_shadow = train_test_split(\n",
    "    X_train, y_train, test_size=1 / 2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# downsample X_test and y_test to 100 samples\n",
    "X_test = X_test[:100]\n",
    "y_test = y_test[:100]\n",
    "\n",
    "#converting labels to int64\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "y_shadow = y_shadow.astype(np.int64)\n",
    "\n",
    "\n",
    "# We simulate the situation where the distribution of training dataset is different from the test/shadow datasets.\n",
    "X_test = 0.5 * X_test + 0.5 * np.random.normal(size=(X_test.shape))\n",
    "X_test=X_test.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = NumpyDataset(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=4, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin1 = nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.lin1(x)\n",
    "        return out\n",
    "    \n",
    "# Train the victim\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated epsilon is 32.73221302406533\n",
      "epoch 0: loss is 2.237553165785631\n",
      "epoch 1: loss is 1.981709357368889\n",
      "epoch 2: loss is 1.5667168422448403\n",
      "epoch 3: loss is 1.263464651343347\n",
      "epoch 4: loss is 1.1401791267085997\n",
      "epoch 5: loss is 0.9982775874563448\n",
      "epoch 6: loss is 0.8367263239896938\n",
      "epoch 7: loss is 0.8118689777258317\n",
      "epoch 8: loss is 0.7478223530409965\n",
      "epoch 9: loss is 0.6460464630438666\n",
      "final epsilon is 29.544385543562118\n"
     ]
    }
   ],
   "source": [
    "lot_size = 40\n",
    "batch_size = 1\n",
    "iterations = 10\n",
    "sigma = 0.5\n",
    "l2_norm_clip = 1\n",
    "delta = 1e-5\n",
    "\n",
    "accountant = GeneralMomentAccountant(\n",
    "    noise_type=\"Gaussian\",\n",
    "    search=\"ternary\",\n",
    "    precision=0.001,\n",
    "    order_max=1,\n",
    "    order_min=72,\n",
    "    max_iterations=1000,\n",
    "    bound_type=\"rdp_upperbound_closedformula\",\n",
    "    backend=\"python\",\n",
    ")\n",
    "\n",
    "privacy_manager = DPSGDManager(\n",
    "    accountant,\n",
    "    optim.SGD,\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    dataset=trainset,\n",
    "    lot_size=lot_size,\n",
    "    batch_size=batch_size,\n",
    "    iterations=iterations,\n",
    ")\n",
    "\n",
    "accountant.reset_step_info()\n",
    "accountant.add_step_info(\n",
    "    {\"sigma\": sigma},\n",
    "    lot_size / len(trainset),\n",
    "    iterations * (len(trainset) / lot_size),\n",
    ")\n",
    "estimated_epsilon = accountant.get_epsilon(delta=delta)\n",
    "print(f\"estimated epsilon is {estimated_epsilon}\")\n",
    "\n",
    "accountant.reset_step_info()\n",
    "dpoptimizer_cls, lot_loader, batch_loader = privacy_manager.privatize(\n",
    "    noise_multiplier=sigma\n",
    ")\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = dpoptimizer_cls(net.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "    running_loss = 0\n",
    "    data_size = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    for X_lot, y_lot in lot_loader(optimizer):\n",
    "        for X_batch, y_batch in batch_loader(TensorDataset(X_lot, y_lot)):\n",
    "            optimizer.zero_grad()\n",
    "            pred = net(X_batch)\n",
    "            loss = criterion(pred, y_batch.to(torch.int64))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            data_size += X_batch.shape[0]\n",
    "            preds.append(pred)\n",
    "            labels.append(y_batch)\n",
    "\n",
    "    preds = torch.cat(preds)\n",
    "    labels = torch.cat(labels)\n",
    "    print(f\"epoch {epoch}: loss is {running_loss/data_size}\")\n",
    "\n",
    "print(f\"final epsilon is {accountant.get_epsilon(delta=delta)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is:  0.772\n"
     ]
    }
   ],
   "source": [
    "in_preds = []\n",
    "in_label = []\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        in_preds.append(outputs)\n",
    "        in_label.append(labels)\n",
    "    in_preds = torch.cat(in_preds)\n",
    "    in_label = torch.cat(in_label)\n",
    "print(\n",
    "    \"Test Accuracy is: \",\n",
    "    accuracy_score(np.array(torch.argmax(in_preds, axis=1)), np.array(in_label)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to wrap the torch module with TorchClassifier\n",
    "clf = TorchClassifier(\n",
    "    net, criterion, optimizer, batch_size=64, epoch=100, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the attacker\n",
    "\n",
    "\n",
    "def create_clf():\n",
    "    _net = Net().to(device)\n",
    "    _optimizer = optim.Adam(_net.parameters(), lr=0.001)\n",
    "    return TorchClassifier(\n",
    "        _net, criterion, _optimizer, batch_size=64, epoch=100, device=device\n",
    "    )\n",
    "\n",
    "\n",
    "shadow_models = [create_clf() for _ in range(2)]\n",
    "attack_models = [SVC(probability=True) for _ in range(10)]\n",
    "\n",
    "attacker = ShadowMembershipInferenceAttack(clf, shadow_models, attack_models)\n",
    "attacker.fit(X_shadow, y_shadow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5233333333333333\n",
      "Precision:  0.9246031746031746\n",
      "Recall:  0.466\n",
      "F1:  0.6196808510638299\n",
      "AUC:  0.638\n"
     ]
    }
   ],
   "source": [
    "# Get the attack result of membership inference\n",
    "in_result = attacker.predict(clf.predict_proba(X_train), y_train)\n",
    "out_result = attacker.predict(clf.predict_proba(X_test), y_test)\n",
    "\n",
    "in_label = np.ones(in_result.shape[0])\n",
    "out_label = np.zeros(out_result.shape[0])\n",
    "\n",
    "att_acc=accuracy_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")\n",
    "\n",
    "\n",
    "att_pr=precision_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")\n",
    "\n",
    "att_r=recall_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")\n",
    "\n",
    "att_f1=f1_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")\n",
    "\n",
    "att_auc=roc_auc_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")\n",
    "\n",
    "print(\"Accuracy: \",att_acc)\n",
    "print(\"Precision: \",att_pr)\n",
    "print(\"Recall: \",att_r)\n",
    "print(\"F1: \",att_f1)\n",
    "print(\"AUC: \",att_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
