{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLEARN VARIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from aijack.attack.membership import ShadowMembershipInferenceAttack\n",
    "from aijack.utils.utils import TorchClassifier, NumpyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1977/3541508647.py:49: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = y_train.astype(np.long)\n",
      "/tmp/ipykernel_1977/3541508647.py:50: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = y_test.astype(np.long)\n",
      "/tmp/ipykernel_1977/3541508647.py:51: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_shadow = y_shadow.astype(np.long)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#load mnist dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "#import shuffle from sklearn\n",
    "from sklearn.utils import shuffle\n",
    "#one hot encode from sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#shuffle the dataset\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "\n",
    "# downsample X_train and y_train to 1000 samples\n",
    "X_train = X_train[:1000]\n",
    "y_train = y_train[:1000]\n",
    "\n",
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)\n",
    "# reshaping data\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "#normalizing data\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#splitting train dataset into train and shadow dataset\n",
    "X_train, X_shadow, y_train, y_shadow = train_test_split(\n",
    "    X_train, y_train, test_size=1 / 2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# downsample X_test and y_test to 100 samples\n",
    "X_test = X_test[:100]\n",
    "y_test = y_test[:100]\n",
    "\n",
    "#converting labels to int64\n",
    "y_train = y_train.astype(np.long)\n",
    "y_test = y_test.astype(np.long)\n",
    "y_shadow = y_shadow.astype(np.long)\n",
    "\n",
    "\n",
    "# We simulate the situation where the distribution of training dataset is different from the test/shadow datasets.\n",
    "X_test = 0.5 * X_test + 0.5 * np.random.normal(size=(X_test.shape))\n",
    "X_test=X_test.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the victim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98, 0.17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the victim\n",
    "\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_train, y_train), clf.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the attacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the attacker\n",
    "\n",
    "shadow_models = [SVC(probability=True) for _ in range(2)]\n",
    "attack_models = [SVC(probability=True) for _ in range(10)]\n",
    "\n",
    "attacker = ShadowMembershipInferenceAttack(clf, shadow_models, attack_models)\n",
    "attacker.fit(X_shadow, y_shadow)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the attack result of membership inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the attack result of membership inference\n",
    "in_result = attacker.predict(clf.predict_proba(X_train), y_train)\n",
    "out_result = attacker.predict(clf.predict_proba(X_test), y_test)\n",
    "\n",
    "in_label = np.ones(in_result.shape[0])\n",
    "out_label = np.zeros(out_result.shape[0])\n",
    "\n",
    "accuracy_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTORCH VARIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LM, self).__init__()\n",
    "        self.lin1 = nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.lin1(x)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the victim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TorchClassifier(batch_size=64, criterion=CrossEntropyLoss(),\n",
       "                 device=device(type='cpu'), epoch=100,\n",
       "                 model=LM(\n",
       "   (lin1): Linear(in_features=784, out_features=10, bias=True)\n",
       " ),\n",
       "                 optimizer=Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " )),\n",
       " 0.52)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the victim\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = LM().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# You need to wrap the torch module with TorchClassifier\n",
    "clf = TorchClassifier(\n",
    "    net, criterion, optimizer, batch_size=64, epoch=100, device=device\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train),clf.score(X_test, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the attacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the attacker\n",
    "\n",
    "\n",
    "def create_clf():\n",
    "    _net = LM().to(device)\n",
    "    _optimizer = optim.Adam(_net.parameters(), lr=0.001)\n",
    "    return TorchClassifier(\n",
    "        _net, criterion, _optimizer, batch_size=64, epoch=100, device=device\n",
    "    )\n",
    "\n",
    "\n",
    "shadow_models = [create_clf() for _ in range(2)]\n",
    "attack_models = [SVC(probability=True) for _ in range(10)]\n",
    "\n",
    "attacker = ShadowMembershipInferenceAttack(clf, shadow_models, attack_models)\n",
    "attacker.fit(X_shadow, y_shadow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7383333333333333\n",
      "Precision:  0.9193154034229829\n",
      "Recall:  0.752\n",
      "F1:  0.8272827282728272\n",
      "AUC:  0.7109999999999999\n"
     ]
    }
   ],
   "source": [
    "# Get the attack result of membership inference\n",
    "in_result = attacker.predict(clf.predict_proba(X_train), y_train)\n",
    "out_result = attacker.predict(clf.predict_proba(X_test), y_test)\n",
    "\n",
    "in_label = np.ones(in_result.shape[0])\n",
    "out_label = np.zeros(out_result.shape[0])\n",
    "\n",
    "att_acc=accuracy_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")\n",
    "\n",
    "\n",
    "att_pr=precision_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")\n",
    "\n",
    "att_r=recall_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")\n",
    "\n",
    "att_f1=f1_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")\n",
    "\n",
    "att_auc=roc_auc_score(\n",
    "    np.concatenate([in_label, out_label]), np.concatenate([in_result, out_result])\n",
    ")\n",
    "\n",
    "print(\"Accuracy: \",att_acc)\n",
    "print(\"Precision: \",att_pr)\n",
    "print(\"Recall: \",att_r)\n",
    "print(\"F1: \",att_f1)\n",
    "print(\"AUC: \",att_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
